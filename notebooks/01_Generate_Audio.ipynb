{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ae8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### IMPORT ######\n",
    "import torch \n",
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import scipy.io.wavfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7b4d07-e25b-495e-8813-3973d96f371e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your device is cpu: it may takes more time, be patientüòÅ\n"
     ]
    }
   ],
   "source": [
    "###### VERIFYNG IF GPU IS AVAILABLE ######\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device == 'cuda:0':\n",
    "    print(f'your device is {device}')\n",
    "else:\n",
    "    print(f'your device is {device}: it may takes more time, be patientüòÅ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4290f79-b552-436c-b4a4-31d0365727e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### LOADING PROCESSOR AND MODEL FROM HUGGING FACEü§ó ######\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7efbbc-936e-4380-b583-10af4b69dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### DEFINING PROMPTS ######\n",
    "prompts = [\n",
    "    \"A 90s rock song with a distorted guitar and a fast drum beat\",\n",
    "    \"A calm relaxing lofi hip hop beat for studying\",\n",
    "    \"Epic cinematic music for a fantasy movie trailer\",\n",
    "    \"A simple melancholic piano solo\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6266a1-f8f5-408f-82bf-0dd61808665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SETTING AUDIO DURATION ######\n",
    "duration_in_seconds = 10\n",
    "duration_in_tokens = int(duration_in_seconds * 50) \n",
    "# MusicGen uses an encoding-decoding model called EnCodec, which compresses audio into a \n",
    "# discrete sequence of tokens and vice versa. According to the official MusicGen \n",
    "# documentation, EnCodec operates at a frequency of 50 Hz. That means the model generates \n",
    "# 50 tokens for every second of audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938f19b1-44ab-4396-b197-6d5deded9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### DEFINING THE DIRECTORY WHERE WE'RE GOING TO SAVE THE GENERATED AUDIOS ######\n",
    "audios_dir = '../data/generated/'\n",
    "os.makedirs(audios_dir, exist_ok=True) # creates the directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17e9945-2e68-4f19-aced-c33dbbb4af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sample 1/4...\n",
      "sample 1 generated and saved succesfully in ../data/generated/sample_1_a_90s_rock_song_with.wav!\n",
      "\n",
      "generating sample 2/4...\n",
      "sample 2 generated and saved succesfully in ../data/generated/sample_2_a_calm_relaxing_lofi.wav!\n",
      "\n",
      "generating sample 3/4...\n",
      "sample 3 generated and saved succesfully in ../data/generated/sample_3_epic_cinematic_music.wav!\n",
      "\n",
      "generating sample 4/4...\n",
      "sample 4 generated and saved succesfully in ../data/generated/sample_4_a_simple_melancholic.wav!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### CREATING AND SAVING AUDIOS ######\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f'generating sample {i+1}/{len(prompts)}...')\n",
    "\n",
    "    # processing prompts \n",
    "    inputs = processor(\n",
    "        text = [prompt], # the text it has to translate\n",
    "        padding = True,  # not usefull in this specific case, it's only for more robust code. It's used to make all prompts the same\n",
    "                         # length if we pass more than one at a time, so that it can return a rectangular tensor.\n",
    "        return_tensors = 'pt' # we're saying \"return a Pytorch Tensor please!\"\n",
    "    ).to(device)\n",
    "\n",
    "    # generating audios\n",
    "    audio_values = model.generate(**inputs, max_new_tokens=duration_in_tokens)\n",
    "\n",
    "    #¬†preparing audios for saving\n",
    "    sampling_rate = model.config.audio_encoder.sampling_rate # It accesses model's technical data sheet (config),\n",
    "                                                             # navigates to the audio_encoder section and reads the\n",
    "                                                             # sampling_rate at which the model's audio should be interpreted.\n",
    "                                                             # For Musicgen-small this value is 32 kHz.\n",
    "    \n",
    "    audio_array = audio_values.cpu().numpy().squeeze() # Pytorch tensor is converted to a NumPy array as that's the format \n",
    "                                                       # understood by SciPy. Each number of this array represents the amplitude \n",
    "                                                       # of the sound wave at a specific moment in time.\n",
    "\n",
    "    #¬†saving audios \n",
    "    prompt_name_as_file = prompt.lower().replace(\" \", \"_\")[:20]\n",
    "    output_path = os.path.join(audios_dir, f\"sample_{i+1}_{prompt_name_as_file}.wav\") \n",
    "    scipy.io.wavfile.write(output_path, rate=sampling_rate, data=audio_array)\n",
    "        # That literally means \"take this data (audio_array) and save the file in this directory (output_path) by using this audio quality\n",
    "        # (sampling_rate)\"\n",
    "\n",
    "        # A .wav file is like a container that holds not only the list of numbers (audio_array) but also essential information \n",
    "        # needed to interpret it, including the sampling rate: when the audio player reads this value it understands that to reproduce the\n",
    "        # audio, it has to read (for example) 32.000 numbers from the array each second and send them to the speaker.\n",
    "    print(f'sample {i+1} generated and saved succesfully in {output_path}!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36025fc-8989-4c59-9583-b2f11fa899dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
